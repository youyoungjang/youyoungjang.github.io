---
layout: post
title: Recsys 2022 paper 리뷰
subtitle: 주요 논문을 살펴보고 응용 방안에 대해 생각해봅니다.
cover-img: /assets/img/recsys/cover.jpg
thumbnail-img: /assets/img/recsys/og.jpg
share-img: /assets/img/recsys/cover.jpg
tags: [recsys, ml, papers]
---

본 글에서는 [Recsys2022](https://recsys.acm.org/recsys22/accepted-contributions/)에서 확인할 수 있었던 흥미로운 논문들 중 일부를 리뷰하고 정리해보도록 하겠습니다.  

## Papers  
### Two-layer Bandit Optimization for Recommendations (Apple)  
- [논문 원본](https://dl.acm.org/doi/abs/10.1145/3523227.3547396)  

app marketplace에서 수 많은 앱 목록을 개인화된 알고리즘을 통해 노출시킨다고 하면 여러 어려움에 직면할 수 있습니다. item(앱) 종류가 매우 다양하고 시시각각으로 변한다는 것 외에도 cannibalization이 발생할 수 있습니다. 예를 들어 특정 앱을 우선적으로 추천한다고 할 때 어쩌면 어떤 user는 그 item을 다운로드 받은 후 더 이상 필요한 앱을 찾아보지 않고 marketplace를 떠나버릴지도 모릅니다.  

**apple**에서는 이러한 문제를 해결하기 위해 굉장히 이해하기 쉬우면서도 효과적인 추천 시스템을 설계했습니다. 그들의 목표는 전체적인 engagement를 저해하지 않으면서도 **추천한(Suggested)** item의 engagement를 증가시키는 것이었습니다.  

논문에서는 `Two-layer Bandit` 구조가 제안되었습니다. 아래와 크게 `Bandit Recall Layer`와 `Bandit Ranking Layer`로 구성됩니다.  

![structure](/assets/img/recsys/apple.PNG){: .mx-auto.d-block :}

전자는 candidate들을 선정하고, 후자는 최종 랭킹을 결정하게 됩니다. update를 위해 **cohort-level effective rewards** 데이터가 수집됩니다. cohort-level로 reward를 계산한다는 부분이 색다르게 느껴집니다. user-level이 아니라 cohort-level로 reward를 계산하게 되면 어쩌면 완벽하게 초개인화가 이루어질 수는 없을지 언정 실제 시스템을 운영할 때의 효율은 훨씬 향상될 수도 있을 것입니다. 유사한 취향을 가진 고객들을 `K-Means` 알고리즘을 통해 grouping하고 이를 바탕으로 cohort를 구성합니다.  

논문에서는 **effective rewards**를 아래와 같이 정의하였습니다.  

$$
F_{\text CC}(i, C_j) = {\text max} (S^i_{C_j} - D^i_{C_j}, 1)
$$  

여기서 $i$ 는 item index를 의미하고, $C_j$ 는 $j$ 번째 cohort를 의미합니다. $S$ 는 검색을 한 번이라고 하고 item을 다운로드 받은 적이 있는 user session의 수를 의미하고 $D$ 는 검색 없이 다운로드 한 user session의 수를 의미합니다. 즉 이러한 reward 설계는 cannibalization을 방지하겠다는 의도를 담고 있습니다.  

만약에 cannibalization을 고려할 필요가 없다고 한다면 $S$ 만 고려해도 될 것입니다. 혹은 다운로드 수 뿐만 아니라 좀 더 다양한 요소를 반영하고 싶다면 reward 식을 더 복잡하게 개량할 수도 있을 것입니다.  

**Bandit Recall Layer**의 핵심은 각 cohort에게 너무 어울리지 않을 법한 item을 빼고 추천 후보 리스트를 만드는 것입니다. 이 때의 기준은 `conversion rate`이 됩니다.  

각 cohort-item pair에 대하여 로그 데이터를 활용하여 모든 empirical conversion rate을 구해줍니다. 그리고 conversion rate이 이항 분포를 통해 형성되었다고 가정하고 CLT를 활용하여 정규분포 형태로 바꿔줍니다. 그리고 여기서 각 cohort-item pair에 대해 `95% LCB: Lower Confidence Bound`를 계산하고 특정 임계값을 넘는 pair만 남겨둡니다. 그리고 각 cohort에 대해 후보 item들의 선택받을 확률을 softmax 함수를 통해 구성해주면 됩니다. 논문에서는 수백 개 정도의 item을 남겨두었다고 기술하고 있습니다.  

보통 `UCB: Upper Confidence Bound`를 적용하는 사례를 많이 보게 되는데, 이 논문에서는 `LCB`를 적용하였습니다. 왜냐하면 이 단계는 최종 단계가 아닌 item 후보 목록을 선정하는 단계이기 때문에 가장 relevant한 item을 찾는 것보다 irrelvant한 item을 걸러내는 것이 더 중요한 작업이기 때문입니다.  

LCB Sampling 과정이 끝나면 `Thompson Sampling` 전략이 적용된 **Bandit Ranking Layer**가 이어집니다. 샘플링은 다음과 같은 분포에 의거하여 이루어집니다.  

$$
{\text Beta}(\alpha = F_{CC}(i, C_j), \beta = I^i_{C_j})
$$  

위 과정을 통해 relevant한 item을 선별하고 추가적으로 uniform sampling을 통해 cold item이 소외받지 않도록 해줍니다. 이를 통해 모델의 confirmation bias를 줄일 수 있습니다. 계속 같은 item을 보여줄 수는 없으니까요.  

실험의 결과는 물론 단순 uniform sampling 보다 위와 같은 `Two-layer Bandit` 구조가 우수하다는 것을 증명합니다. 그런데 흥미로운 부분은, LCB와 달리 Thompson Sampling만을 적용했을 때 Cannibalization 현상이 발생했다는 점입니다.  

![table](/assets/img/recsys/apple2.PNG){: .mx-auto.d-block :}

만약 Thompson Sampling만을 이용했다면 비록 relevance는 올라갔을 수 있지만 실제로 서비스에서 추구하는 결과와는 좀 멀어졌을 수도 있겠다는 생각이 드는 대목이었습니다. LCB sampling와 uniform sampling을 함께 적용함으로써 균형적인 결과를 얻을 수 있었던 것으로 보였습니다.  


## References  
- [RecSys 2022 - Recap, Favorite Papers, and Lessons](https://eugeneyan.com/writing/recsys2022/)  

